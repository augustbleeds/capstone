{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports and Constants\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from operator import add\n",
    "import socket\n",
    "\n",
    "## Our pretrained model that predicts the rectangles that correspond to the facial features of a face\n",
    "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "CASCADE_PATH='Haarcascades/haarcascade_frontalface_default.xml'\n",
    "\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "JAW_POINTS = list(range(0, 17))\n",
    "AVG = None\n",
    "\n",
    "# Points used to line up the images.\n",
    "ALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS +\n",
    "                               RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS)\n",
    "\n",
    "# Points from the second image to overlay on the first. The convex hull of each\n",
    "# element will be overlaid.\n",
    "OVERLAY_POINTS = [\n",
    "    LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
    "    NOSE_POINTS + MOUTH_POINTS,\n",
    "]\n",
    "\n",
    "# bounding box\n",
    "CASCADE = cv2.CascadeClassifier(CASCADE_PATH)\n",
    "DETECTOR = dlib.get_frontal_face_detector()\n",
    "\n",
    "# facial landmarks\n",
    "PREDICTOR = dlib.shape_predictor(PREDICTOR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Live Landmark Functions\n",
    "\n",
    "def get_landmarks(im, dlibOn, const_rect=None, show_rect=False):\n",
    "    if const_rect == None:\n",
    "        pass\n",
    "    else:\n",
    "        s = const_rect  # (79, 51) (208, 180)\n",
    "        if show_rect:\n",
    "            draw_rect(im, s)\n",
    "        rect = dlib.rectangle(s[0][0], s[0][1], s[1][0], s[1][1])\n",
    "        a = np.matrix([[p.x, p.y] for p in PREDICTOR(im, rect).parts()])\n",
    "        \n",
    "        if a is None:\n",
    "            print(\"no a\")\n",
    "            return None\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    if dlibOn:\n",
    "        rects = DETECTOR(im, 1)\n",
    "        if len(rects) != 1:\n",
    "            print(\"incorrect number of faces\")\n",
    "            return None\n",
    "\n",
    "        if show_rect:\n",
    "            draw_rect(im, dlib_rect_to_tuple(rects[0]))\n",
    "            #print(rects[0].left())\n",
    "        a = np.matrix([[p.x, p.y] for p in PREDICTOR(im, rects[0]).parts()])\n",
    "        return a\n",
    "    \n",
    "    else:\n",
    "        rects = CASCADE.detectMultiScale(im, 1.3, 5, flags=cv2.cv.CV_HAAR_SCALE_IMAGE)\n",
    "        if len(rects) != 1:\n",
    "            print(\"incorrect number of faces\")\n",
    "            return None\n",
    "        \n",
    "        x,y,w,h = rects[0]\n",
    "        \n",
    "        x = long(x)\n",
    "        y = long(y)\n",
    "        rect=dlib.rectangle(x,y,x+w,y+h)\n",
    "        if show_rect:\n",
    "            draw_rect(im, rect)\n",
    "        return np.matrix([[p.x, p.y] for p in PREDICTOR(im, rect).parts()])\n",
    "\n",
    "    \n",
    "def annotate_landmarks(im, landmarks):\n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        #cv2.putText(im, str(idx), pos,\n",
    "        #            fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "        #            fontScale=0.4,\n",
    "        #            color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
    "    return im\n",
    "\n",
    "\n",
    "def face_swap(img, name, cr=None):\n",
    "\n",
    "    s = get_landmarks(img,True, const_rect=cr)\n",
    "    \n",
    "    if not s:\n",
    "        print \"No or too many faces\"\n",
    "        return img\n",
    "    \n",
    "    img = annotate_landmarks(img, s)\n",
    "    img = draw_rect(img, s[0])\n",
    "    \n",
    "    #frame = cv2.resize(image,None,fx=4, fy=4, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    return image \n",
    "\n",
    "\n",
    "# draw rectangle (79, 51) (208, 180)\n",
    "def draw_rect(img, s):\n",
    "    if not s:\n",
    "        return img\n",
    "\n",
    "    a = s[0]\n",
    "    b = s[1]\n",
    "    cv2.line(frame, a,           (a[0],b[1]), (255,0,0))\n",
    "    cv2.line(frame, (a[0],b[1]), b,           (255,0,0))\n",
    "    cv2.line(frame, b,           (b[0],a[1]), (255,0,0))\n",
    "    cv2.line(frame, (b[0],a[1]), a,           (255,0,0))\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def open_camera(num=-1):\n",
    "    cap = cv2.VideoCapture(num)\n",
    "    if cap.isOpened():\n",
    "        #print(\"got cam\")\n",
    "        return cap\n",
    "    else:\n",
    "        print(\"no cam\")\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "    \n",
    "def dlib_rect_to_tuple(rect):\n",
    "    return [(rect.left(), rect.top()), (rect.right(), rect.bottom())]\n",
    "\n",
    "pose_pts = (30, 8, 36, 45, 48, 54)\n",
    "# 3D model points.\n",
    "model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                            (0.0, -330.0, -65.0),        # Chin\n",
    "                            (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                        \n",
    "                        ])\n",
    "\n",
    "\n",
    "def get_relevant_pts(landmarks):\n",
    "    a = []\n",
    "    for i in range(len(pose_pts)):\n",
    "        a.append( (landmarks[pose_pts[i],0], landmarks[pose_pts[i],1]) )\n",
    "    return np.array(a, dtype='double')\n",
    "\n",
    "\n",
    "def put_pose(im, image_points):\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points,\\\n",
    "                                                                  camera_matrix, dist_coeffs, flags=cv2.CV_ITERATIVE)\n",
    "\n",
    "    #print \"Rotation Vector:\\n {0}\".format(rotation_vector)\n",
    "    #print \"Translation Vector:\\n {0}\".format(translation_vector)\n",
    "    \n",
    "\n",
    "    # Project a 3D point (0, 0, 500.0) onto the image plane.\n",
    "    # We use this to draw a line sticking out of the nose\n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 500.0)]), rotation_vector,\\\n",
    "                                                 translation_vector, camera_matrix, dist_coeffs)\n",
    "\n",
    "    for p in image_points:\n",
    "        cv2.circle(im, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
    "\n",
    "\n",
    "    p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
    "    p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "\n",
    "    cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "    \n",
    "    return (rotation_vector, translation_vector)\n",
    "    \n",
    "\n",
    "TIME = None\n",
    "F_COUNT = 0\n",
    "F_RATE = 0\n",
    "def put_frame_rate_and_vectors(im, vectors=None):\n",
    "    global TIME\n",
    "    global F_COUNT\n",
    "    global F_RATE\n",
    "    \n",
    "    pos = (30,30)\n",
    "    t = time.clock()\n",
    "\n",
    "    diff = t - TIME\n",
    "    F_COUNT += 1\n",
    "    \n",
    "    if diff > 1:\n",
    "        TIME = t\n",
    "        F_RATE = F_COUNT\n",
    "        F_COUNT = 0\n",
    "        \n",
    "    cv2.putText(im, str(F_RATE),\n",
    "                pos,\n",
    "                fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                fontScale=0.4,\n",
    "                color=(0, 0, 0))\n",
    "    \n",
    "    if vectors:\n",
    "        cv2.putText(im, \"R: ({:+f},{:+f},{:+f})\".format(vectors[0][0,0]*(180/3.14), vectors[0][1,0]*(180/3.14), vectors[0][2,0]*(180/3.14)),\n",
    "        #cv2.putText(im, \"R: ({:+f})\".format(vectors[0][0,0]),\n",
    "                (pos[0], pos[1]+20),\n",
    "                fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                fontScale=0.6,\n",
    "                thickness=2,\n",
    "                color=(0, 0, 255))\n",
    "        cv2.putText(im, \"T: ({:+f},{:+f},{:+f})\".format(vectors[1][0,0], vectors[1][1,0], vectors[1][2,0]),\n",
    "                (pos[0], pos[1]+40),\n",
    "                fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                fontScale=0.6,\n",
    "                thickness=2,\n",
    "                color=(0, 0, 255))\n",
    "    else:\n",
    "        cv2.putText(im, \"@@@\",\n",
    "                (pos[0], pos[1]+20),\n",
    "                fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                fontScale=0.4,\n",
    "                color=(255, 0, 0))\n",
    "        \n",
    "    \n",
    "    return im\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening...\n",
      "('Connected: ', ('127.0.0.1', 57974))\n",
      "('', 'asdf\\r\\n')\n",
      "('', '\\r\\n')\n",
      "Connection Closed.\n"
     ]
    }
   ],
   "source": [
    "# Socket server\n",
    "\n",
    "import socket\n",
    "HOST = \"localhost\"\n",
    "PORT = 10000\n",
    "\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "sock.bind( (HOST,PORT) )\n",
    "print(\"listening...\")\n",
    "sock.listen(1)\n",
    "\n",
    "conn, addr = sock.accept()\n",
    "print(\"Connected: \", addr)\n",
    "while 1:\n",
    "    data = conn.recv(1024)\n",
    "    print(\"\",data)\n",
    "    if data.strip() == \"\":\n",
    "        \n",
    "        break\n",
    "    conn.sendall(data) #mirrors\n",
    "conn.close()\n",
    "\n",
    "print(\"Connection Closed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Matrix :\n",
      " [[ 640.    0.  320.]\n",
      " [   0.  640.  240.]\n",
      " [   0.    0.    1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/home/bob/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:62: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/home/bob/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:68: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/home/bob/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:56: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "\n",
    "# Name is the image we want to swap onto ours\n",
    "# dlibOn controls if use dlib's facial landmark detector (better) \n",
    "# or use HAAR Cascade Classifiers (faster)\n",
    "cap = open_camera(-1)\n",
    "if not cap:\n",
    "    sys.exit()\n",
    "    \n",
    "ret, frame = cap.read()\n",
    "size = frame.shape\n",
    "    \n",
    "# Camera internals\n",
    "focal_length = size[1]\n",
    "center = (size[1]/2, size[0]/2)\n",
    "camera_matrix = np.array(\n",
    "                         [[focal_length, 0, center[0]],\n",
    "                         [0, focal_length, center[1]],\n",
    "                         [0, 0, 1]], dtype = \"double\"\n",
    "                        )\n",
    "print \"Camera Matrix :\\n {0}\".format(camera_matrix);\n",
    "dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "\n",
    "\n",
    "dlibOn = False\n",
    "counter = 0\n",
    "landmarks = None\n",
    "prev_landmarks = None\n",
    "TIME = time.clock()\n",
    "\n",
    "\n",
    "while True:\n",
    "    counter += 1\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    #Reduce image size by 75% to reduce processing time and improve framerates\n",
    "    #frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    # flip image so that it's more mirror like\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    face_box = [(179,151), (456,440)]\n",
    "    #face_box = None\n",
    "    \n",
    "    # No processing\n",
    "    #cv2.imshow('window_name', frame)\n",
    "    #if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "    #    break\n",
    "    #continue\n",
    "    \n",
    "    landmarks = get_landmarks(frame, True, const_rect=face_box, show_rect=True)\n",
    "    \n",
    "    if landmarks != None and counter > 1: #average 2 frames, less jitter\n",
    "        if prev_landmarks != None:\n",
    "            landmarks = np.add(landmarks, prev_landmarks)\n",
    "        landmarks //= 2\n",
    "        prev_landmarks = landmarks\n",
    "        # TODO: avg x by adding and subtracting (curr and oldest)\n",
    "        \n",
    "    if landmarks != None:  # annotating landmarks, adding lines\n",
    "        frame = annotate_landmarks(frame, landmarks)\n",
    "        cv2.line(frame, (landmarks[36,0],landmarks[36,1]), (landmarks[45,0],landmarks[45,1]), (255,0,0))\n",
    "        #print((landmarks[36,0],landmarks[36,1]), (landmarks[45,0],landmarks[45,1]))\n",
    "        \n",
    "    vectors = None\n",
    "    if landmarks != None:  # adds pose estimation\n",
    "        a = get_relevant_pts(landmarks)\n",
    "        vectors = put_pose(frame, a)\n",
    "        \n",
    "    frame = put_frame_rate_and_vectors(frame, vectors=vectors)\n",
    "    cv2.imshow('window_name', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Matrix :\n",
      " [[  1.20000000e+03   0.00000000e+00   6.00000000e+02]\n",
      " [  0.00000000e+00   1.20000000e+03   3.37000000e+02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "Rotation Vector:\n",
      " [[-0.0581844 ]\n",
      " [ 2.20231074]\n",
      " [ 0.01887552]]\n",
      "Translation Vector:\n",
      " [[  449.53365497]\n",
      " [  -95.72475146]\n",
      " [-2344.07917989]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read Image\n",
    "#cap = cv2.VideoCapture(-1)\n",
    "#print(\"got cam,\",cap.isOpened())\n",
    "#if not cap.isOpened():\n",
    "#    cap.release()\n",
    "#    sys.exit(0)\n",
    "im = cv2.imread(\"headPose.jpg\");\n",
    "#ret, im = cap.read()\n",
    "size = im.shape\n",
    "    \n",
    "#2D image points. If you change the image, you need to change vector\n",
    "image_points = np.array([\n",
    "                            (359, 391),     # Nose tip\n",
    "                            (399, 561),     # Chin\n",
    "                            (337, 297),     # Left eye left corner\n",
    "                            (513, 301),     # Right eye right corne\n",
    "                            (345, 465),     # Left Mouth corner\n",
    "                            (453, 469)      # Right mouth corner\n",
    "                        ], dtype=\"double\")\n",
    "\n",
    "# 3D model points.\n",
    "model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                            (0.0, -330.0, -65.0),        # Chin\n",
    "                            (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                        \n",
    "                        ])\n",
    "\n",
    "\n",
    "# Camera internals\n",
    "focal_length = size[1]\n",
    "center = (size[1]/2, size[0]/2)\n",
    "camera_matrix = np.array(\n",
    "                         [[focal_length, 0, center[0]],\n",
    "                         [0, focal_length, center[1]],\n",
    "                         [0, 0, 1]], dtype = \"double\"\n",
    "                         )\n",
    "\n",
    "print \"Camera Matrix :\\n {0}\".format(camera_matrix);\n",
    "\n",
    "dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "\n",
    "\n",
    "(success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.CV_ITERATIVE)\n",
    "\n",
    "print \"Rotation Vector:\\n {0}\".format(rotation_vector)\n",
    "print \"Translation Vector:\\n {0}\".format(translation_vector)\n",
    "\n",
    "\n",
    "# Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "# We use this to draw a line sticking out of the nose\n",
    "\n",
    "\n",
    "(nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "\n",
    "for p in image_points:\n",
    "    cv2.circle(im, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
    "\n",
    "\n",
    "p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
    "p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "\n",
    "cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Output\", im);\n",
    "cv2.waitKey(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
